prompts:
  - task: self_check_facts
    content: |-
      You are given a task to identify if the hypothesis is grounded and entailed to the evidence.
      You will only use the contents of the evidence and not rely on external knowledge.
      Answer with yes/no. "evidence": {{ evidence }} "hypothesis": {{ response }} "entails":
      
  - task: general
    models:
      - meta/llama-3.1-70b-instruct
    
    messages:
      - type: system
        content: |
          {{ general_instructions }}{% if relevant_chunks != None and relevant_chunks != '' %}
          This is some relevant context:
          ```markdown
          {{ relevant_chunks }}
          ```{% endif %}
      - "{{ history | to_chat_messages }}"

  # Prompt for detecting the user message canonical form.
  - task: generate_user_intent
    models:
      - meta/llama-3.1-8b-instruct
    
    messages:
      - type: system
        content: |
          {{ general_instructions }}

          Your task is to generate the user intent in a conversation given the last user message similar to the examples below.
          Do not provide any explanations, just output the user intent.

          # Examples:
          {{ examples | verbose_v1 }}

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"
      - type: assistant
        content: |
            Bot thinking: potential user intents are: {{ potential_user_intents }}

    output_parser: "verbose_v1"

  # Prompt for generating the next steps.
  - task: generate_next_steps
    models:
      - meta/llama-3.1-8b-instruct
    
    messages:
      - type: system
        content: |
          {{ general_instructions }}

          Your task is to generate the next steps in a conversation given the last user message similar to the examples below.
          Do not provide any explanations, just output the user intent and the next steps.

          # Examples:
          {{ examples | remove_text_messages | verbose_v1 }}

      - "{{ sample_conversation | first_turns(2) | to_intent_messages }}"
      - "{{ history | colang | to_intent_messages }}"

    output_parser: "verbose_v1"

  # Prompt for generating the bot message from a canonical form.
  - task: generate_bot_message
    models:
      - meta/llama-3.1-70b-instruct
    
    messages:
      - type: system
        content: |
            {{ general_instructions }}{% if relevant_chunks != None and relevant_chunks != '' %}
            This is some relevant context:
            ```markdown
            {{ relevant_chunks }}
            ```{% endif %}
            Your task is to generate the bot message in a conversation given the last user message, user intent and bot intent.
            Similar to the examples below.
            Clearly state whether you received any relevant context to inform your response.

            # Examples:
            {{ examples | verbose_v1 }}

      - "{{ sample_conversation | first_turns(2) | to_intent_messages_2 }}"
      - "{{ history | colang | to_intent_messages_2 }}"

    output_parser: "verbose_v1"

  # Prompt for generating the user intent, next steps and bot message in a single call.
  - task: generate_intent_steps_message
    models:
      - meta/llama-3.1-8b-instruct

    messages:
      - type: system
        content: |
          {{ general_instructions }}{% if relevant_chunks != None and relevant_chunks != '' %}
          This is some relevant context:
          ```markdown
          {{ relevant_chunks }}
          ```{% endif %}

          Your task is to generate the user intent and the next steps in a conversation given the last user message similar to the examples below.
          Do not provide any explanations, just output the user intent and the next steps.

          # Examples:
          {{ examples | verbose_v1 }}

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"
      - type: assistant
        content: |
            Bot thinking: potential user intents are: {{ potential_user_intents }}

    output_parser: "verbose_v1"

  # Prompt for generating the value of a context variable.
  - task: generate_value
    models:
      - meta/llama-3.1-8b-instruct

    messages:
      - type: system
        content: |
          {{ general_instructions }}

          Your task is to generate value for the ${{ var_name }} variable..
          Do not provide any explanations, just output value.

          # Examples:
          {{ examples | verbose_v1 }}

      - "{{ sample_conversation | first_turns(2) | to_messages }}"
      - "{{ history | colang | to_messages }}"
      - type: assistant
        content: |
            Bot thinking: follow the following instructions: {{ instructions }}
            ${{ var_name }} =

    output_parser: "verbose_v1"