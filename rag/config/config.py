import os
from typing import Optional

from langchain.llms import BaseLLM
from langchain.vectorstores import FAISS
from langchain.text_splitter import TextSplitter, RecursiveCharacterTextSplitter
from langchain_nvidia_ai_endpoints import NVIDIARerank

from langchain_core.retrievers import BaseRetriever

from nemoguardrails import LLMRails, RailsConfig
from nemoguardrails.actions import action
from nemoguardrails.actions.actions import ActionResult
import re
from typing import List, Union

import requests
from bs4 import BeautifulSoup


def init_vectorstore_rerank(config: RailsConfig):
    config.knowledge_base.reranking_provider
    emd_config = config.knowledge_base.reranking_provider

    embedding_model = NVIDIAEmbeddings(
        model=emd_config.parameters.get("embedding_model"),
        base_url=emd_config.parameters.get("base_url"),
        truncate=emd_config.parameters.get("truncate"),
    )
    embedding_path = os.path.join(
        config.config_path,
        os.path.pardir,
        "data",
        "nv_embedding",
    )
    retriever = create_embeddings(
        embedding_model=embedding_model,
        embedding_path=embedding_path,
    )
    return retriever


@action(is_system_action=True)
async def retrieve_relevant_chunks(
    retriever: BaseRetriever,
    context: Optional[dict] = None,
    llm: Optional[BaseLLM] = None,
):
    """Retrieve relevant chunks from the knowledge base and add them to the context."""
    user_message = context.get("last_user_message")
    # only call the retriever as the message will be generated by `generate_bot_message` action
    documents = await retriever.ainvoke(input=user_message)
    citing_text = "\n".join([doc.page_content for doc in documents])
    source_ref = "\n".join([doc.metadata["source"] for doc in documents])

    context_updates = {
        "relevant_chunks": f"""
            Question: {user_message}
            Citing : {citing_text},
            Source : {source_ref}
    """
    }

    return ActionResult(
        return_value=context_updates["relevant_chunks"],
        context_updates=context_updates,
    )


def init(llm_rails: LLMRails):
    if isinstance(llm_rails, LLMRails):
        # check that `llm_rails` is an instance of `LLMRails` as multiple libraries uses the same
        # config.py and `init` methods, e.g. FastAPI
        config = llm_rails.config

        # Initialize the various models
        reranker = init_vectorstore_retriever(config)

        # Register the custom `retrieve_relevant_chunks` for custom retrieval
        llm_rails.register_action(
            action=retrieve_relevant_chunks,
            name="retrieve_relevant_chunks",
        )
        llm_rails.register_action_param(
            name="retriever",
            value=vectorstore_retriever,
        )
