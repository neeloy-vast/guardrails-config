{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Guardrails with RAG for fact-checking\n",
    "\n",
    "In this notebook, we'll demonstrate how to integrate a RAG (Retrieval-Augmented Generation) system using NVIDIA AI Endpoints with NeMo Guardrails for enhanced text generation and fact-checking. While there are many examples of integrating NeMo Guardrails and RAG pipelines using LangChain, this demo showcases how Guardrails can be combined with any RAG system, independent of the `RunnableRails` interface.\n",
    "\n",
    "The workflow is as follows: First, a [vector store](config/config.py#L155) is built using FAISS and NVIDIA NIMs as the [embedding model](./config/config.yml#L13). The content for the vector store is sourced from the NVIDIA Triton documentation webpages, though the code can easily be modified to use any other data source or vector store. Next, NeMo Guardrails is configured to use the initialized vector store for generating bot messages and performing fact-checking.\n",
    "\n",
    "Let's start by installing the required libraries and importing the necessary packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu==1.7.2 # replace with faiss-cpu if you don't have a gpu\n",
    "!pip install langchain==0.2.15\n",
    "!pip install nemoguardrails==0.9.1.1\n",
    "!pip install langchain-nvidia-ai-endpoints==0.1.2\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvidia_api_key.startswith(\n",
    "        \"nvapi-\"\n",
    "    ), f\"{nvidia_api_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the [documentation](https://docs.nvidia.com/nemo/guardrails/introduction.html#guardrails-configuration), the `config.py` file is used for custom initialization of the vector store. Specifically, the [`init` function](./config/config.py#L197) is invoked by the `LLMRails` constructor and serves as the entry point for initializing the vector store. It also instructs Guardrails to use the knowledge base as an additional data source when generating bot messages.\n",
    "\n",
    "By providing a custom implementation of the [`retrieve_relevant_chunks` function](./config/config.py#L171), we enable NeMo Guardrails to retrieve external knowledge from the vector store and inject it into prompts. For example, this is done in the [`generate_bot_message` prompt](./config/prompts.yml#L82), where the `relevant_chunks` variable is added at template time. Note that the `retriever` argument in the retrieve_relevant_chunks function is automatically passed by NeMo Guardrails as it is registered as an [action parameter](./config/config.py#L211).\n",
    "\n",
    "Finally, to activate the `fact-checking` rails, the `self check facts` rule must be added as an output rail in the standard [config.yml](config/config.yml#L21) file required by NeMo Guardrails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:02:05.421</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Registered Actions</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:02:05.421\u001b[0m | \u001b[2;38;2;112;112;112mRegistered Actions\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m['alignscore request', 'alignscore_check_facts', 'autoalign_factcheck_output_api'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scavallari/miniconda3/envs/test-gen-ai/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:556: UserWarning: Found nvidia/nv-embedqa-e5-v5 in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing embeddings to guardrails/rag-fact-check/config/../data/nv_embedding\n",
      "Generated embedding successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scavallari/miniconda3/envs/test-gen-ai/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_common.py:556: UserWarning: Found meta/llama-3.1-405b-instruct in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig\n",
    "\n",
    "config = RailsConfig.from_path(\"guardrails/rag-fact-check/config\")\n",
    "rails = LLMRails(config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.823</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UtteranceUserActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'final_transcript': 'how can I specify the location of the mode</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.823\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUtteranceUserActionFinished\u001b[0m | \u001b[2m{'final_transcript': 'how can I specify the location of the mode\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.828</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'b2a1...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.828\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'b2a1...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.832</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.832\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.834</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UserMessage</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '23d9...', 'text': 'how can I specify the location of the model reposito</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.834\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUserMessage\u001b[0m | \u001b[2m{'uid': '23d9...', 'text': 'how can I specify the location of the model reposito\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.841</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '714b...', 'action_name': 'generate_user_intent', 'action_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.841\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '714b...', 'action_name': 'generate_user_intent', 'action_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.845</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">generate_user_intent</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.845\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mgenerate_user_intent\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.847</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Phase 1</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Generating user intent</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.847\u001b[0m | \u001b[2;38;2;112;112;112mPhase 1\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mGenerating user intent\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:27.863</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:27.863\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System                                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "System                                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are an useful bot that reply to user questions in a useful and truthful way.                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are an useful bot that reply to user questions in a useful and truthful way.                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">If the question uses harmful of violent language, the bot politely refuse to answer.                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mIf the question uses harmful of violent language, the bot politely refuse to answer.                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Your task is to generate the user intent in a conversation given the last user message similar to the examples </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">below.                                                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYour task is to generate the user intent in a conversation given the last user message similar to the examples \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mbelow.                                                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Do not provide any explanations, just output the user intent.                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDo not provide any explanations, just output the user intent.                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\"># Examples:                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m# Examples:                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"What can you help me with?\"                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"What can you help me with?\"                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"What can you do?\"                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"What can you do?\"                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"Hello\"                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"Hello\"                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"tell me about you\"                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"tell me about you\"                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"Hi\"                                                                                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"Hi\"                                                                                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Hello there!                                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mHello there!                                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: express greeting                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: express greeting                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"Hello! How can I assist you today?\"                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"Hello! How can I assist you today?\"                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">What can you do for me?                                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mWhat can you do for me?                                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask about capabilities                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask about capabilities                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond about capabilities                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond about capabilities                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">various topics, generating text for various purposes and providing suggestions based on your preferences.\"         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mvarious topics, generating text for various purposes and providing suggestions based on your preferences.\"         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">how can I specify the location of the model repository in triton-inference-server                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhow can I specify the location of the model repository in triton-inference-server                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot thinking: potential user intents are: ask capabilities, express greeting                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot thinking: potential user intents are: ask capabilities, express greeting                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">User intent: ask technical question                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mUser intent: ask technical question                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.939</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'User intent: ask technical question', 'token_usage': </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.939\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'User intent: ask technical question', 'token_usage': \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.941</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 1.04 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.941\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 1.04 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.942</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UserIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'dc06...', 'intent': 'ask technical question'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.942\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUserIntent\u001b[0m | \u001b[2m{'uid': 'dc06...', 'intent': 'ask technical question'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.944</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '5fed...', 'intent': 'respond to question'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.944\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotIntent\u001b[0m | \u001b[2m{'uid': '5fed...', 'intent': 'respond to question'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.945</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'cd09...', 'action_name': 'retrieve_relevant_chunks', 'act</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.945\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'cd09...', 'action_name': 'retrieve_relevant_chunks', 'act\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:28.948</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">retrieve_relevant_chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:28.948\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mretrieve_relevant_chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:29.594</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">InternalSystemActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7ff7...', 'action_uid': 'f171...', 'action_name': 'ret</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:29.594\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mInternalSystemActionFinished\u001b[0m | \u001b[2m{'uid': '7ff7...', 'action_uid': 'f171...', 'action_name': 'ret\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:29.619</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '1ab7...', 'action_name': 'generate_bot_message', 'action_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:29.619\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '1ab7...', 'action_name': 'generate_bot_message', 'action_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:29.620</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">generate_bot_message</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:29.620\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mgenerate_bot_message\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:29.621</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Phase 3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Generating bot message ...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:29.621\u001b[0m | \u001b[2;38;2;112;112;112mPhase 3\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mGenerating bot message ...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:29.634</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:29.634\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System                                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "System                                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are an useful bot that reply to user questions in a useful and truthful way.                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are an useful bot that reply to user questions in a useful and truthful way.                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">If the question uses harmful of violent language, the bot politely refuse to answer.                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mIf the question uses harmful of violent language, the bot politely refuse to answer.                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">This is some relevant context:                                                                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mThis is some relevant context:                                                                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">```markdown                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m```markdown                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Question: how can I specify the location of the model repository in triton-inference-server                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mQuestion: how can I specify the location of the model repository in triton-inference-server                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Citing : Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Backend Example Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">File System Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Credential file (Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Models TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">setting up a model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">serves models from one or more model repositories that are specified when the server is started. While Triton is </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">running, the models being served can be modified as described in Model Management. Repository Layout# These </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">repository paths are specified when Triton is started using the âmodel-repository option. The âmodel-repository</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">option                                                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Citing : Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mBackend Example Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mFile System Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCredential file (Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mModels TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time \u001b[0m\n",
       "\u001b[30;48;2;144;144;144msetting up a model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mserves models from one or more model repositories that are specified when the server is started. While Triton is \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mrunning, the models being served can be modified as described in Model Management. Repository Layout# These \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mrepository paths are specified when Triton is started using the âmodel-repository option. The âmodel-repository\u001b[0m\n",
       "\u001b[30;48;2;144;144;144moption                                                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">from one or more model repositories that are specified when the server is started. While Triton is running, the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">models being served can be modified as described in Model Management. Repository Layout# These repository paths are</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">specified when Triton is started using the âmodel-repository option. The âmodel-repository option              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDecoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mRepository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mTensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodel repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfrom one or more model repositories that are specified when the server is started. While Triton is running, the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodels being served can be modified as described in Model Management. Repository Layout# These repository paths are\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mspecified when Triton is started using the âmodel-repository option. The âmodel-repository option              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">from one or more model repositories that are specified when the server is started. While Triton is running, the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">models being served can be modified as described in Model Management. Repository Layout# These repository paths are</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">specified when Triton is started using the âmodel-repository option. The âmodel-repository option,             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDecoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mRepository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mTensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodel repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfrom one or more model repositories that are specified when the server is started. While Triton is running, the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodels being served can be modified as described in Model Management. Repository Layout# These repository paths are\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mspecified when Triton is started using the âmodel-repository option. The âmodel-repository option,             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Source : </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Source : \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">```                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m```                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Your task is to generate the bot message in a conversation given the last user message, user intent and bot intent.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYour task is to generate the bot message in a conversation given the last user message, user intent and bot intent.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Similar to the examples below.                                                                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mSimilar to the examples below.                                                                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Do not provide any explanations, just output the bot message.                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDo not provide any explanations, just output the bot message.                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\"># Examples:                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m# Examples:                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform cannot engage with sensitive content                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform cannot engage with sensitive content                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I will not engage with sensitive content.\"                                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I will not engage with sensitive content.\"                                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer unknown                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer unknown                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I don't know the answer to that.\"                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I don't know the answer to that.\"                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer prone to hallucination                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer prone to hallucination                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"The above response may have been hallucinated, and should be independently verified.\"                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"The above response may have been hallucinated, and should be independently verified.\"                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer prone to hallucination                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer prone to hallucination                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">using additional sources.\"                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer\u001b[0m\n",
       "\u001b[30;48;2;144;144;144musing additional sources.\"                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: refuse to respond                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: refuse to respond                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I'm sorry, I can't respond to that.\"                                                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I'm sorry, I can't respond to that.\"                                                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Hello there!                                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mHello there!                                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: express greeting                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: express greeting                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"Hello! How can I assist you today?\"                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"Hello! How can I assist you today?\"                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">What can you do for me?                                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mWhat can you do for me?                                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond about capabilities                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond about capabilities                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">various topics, generating text for various purposes and providing suggestions based on your preferences.\"         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mvarious topics, generating text for various purposes and providing suggestions based on your preferences.\"         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">how can I specify the location of the model repository in triton-inference-server                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhow can I specify the location of the model repository in triton-inference-server                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond to question                                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond to question                                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">Bot message: \"You can specify the location of the model repository in Triton Inference Server using the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">--model-repository option when starting the server. This option allows you to specify one or more model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">repositories that the server will serve models from. You can also modify the models being served while the server </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">is running using Model Management. For more information, please refer to the Triton Inference Server documentation,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">specifically the Architecture section: </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html\"         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mBot message: \"You can specify the location of the model repository in Triton Inference Server using the \u001b[0m\n",
       "\u001b[30;48;2;0;102;0m--model-repository option when starting the server. This option allows you to specify one or more model \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mrepositories that the server will serve models from. You can also modify the models being served while the server \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mis running using Model Management. For more information, please refer to the Triton Inference Server documentation,\u001b[0m\n",
       "\u001b[30;48;2;0;102;0mspecifically the Architecture section: \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html\"         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.634</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'Bot message: \"You can specify the location of the mod</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.634\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'Bot message: \"You can specify the location of the mod\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.640</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 4.94 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.640\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 4.94 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.641</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM Bot Message Generation call took 5.01 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.641\u001b[0m | \u001b[2;38;2;85;85;85mLLM Bot Message Generation call took 5.01 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.642</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotMessage</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7503...', 'text': 'You can specify the location of the model repository </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.642\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotMessage\u001b[0m | \u001b[2m{'uid': '7503...', 'text': 'You can specify the location of the model repository \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.647</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '6e2a...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.647\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '6e2a...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.649</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.649\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.650</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartOutputRails</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '63e3...'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.650\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartOutputRails\u001b[0m | \u001b[2m{'uid': '63e3...'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.653</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'd823...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.653\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'd823...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.656</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.656\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.657</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartOutputRail</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'e00c...', 'flow_id': 'self check facts'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.657\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartOutputRail\u001b[0m | \u001b[2m{'uid': 'e00c...', 'flow_id': 'self check facts'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.660</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'fe93...', 'action_name': 'self_check_facts', 'action_para</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.660\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'fe93...', 'action_name': 'self_check_facts', 'action_para\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.662</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">self_check_facts</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.662\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mself_check_facts\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:34.665</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:34.665\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are given a task to identify if the hypothesis is grounded and entailed to the evidence.                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are given a task to identify if the hypothesis is grounded and entailed to the evidence.                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You will only use the contents of the evidence and not rely on external knowledge.                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou will only use the contents of the evidence and not rely on external knowledge.                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Answer with yes/no. \"evidence\":                                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mAnswer with yes/no. \"evidence\":                                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Question: how can I specify the location of the model repository in triton-inference-server            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Question: how can I specify the location of the model repository in triton-inference-server            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Citing : Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Backend Example Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">File System Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Credential file (Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Models TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">setting up a model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">serves models from one or more model repositories that are specified when the server is started. While Triton is </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">running, the models being served can be modified as described in Model Management. Repository Layout# These </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">repository paths are specified when Triton is started using the âmodel-repository option. The âmodel-repository</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">option                                                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Citing : Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mBackend Example Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mFile System Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCredential file (Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mModels TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time \u001b[0m\n",
       "\u001b[30;48;2;144;144;144msetting up a model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mserves models from one or more model repositories that are specified when the server is started. While Triton is \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mrunning, the models being served can be modified as described in Model Management. Repository Layout# These \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mrepository paths are specified when Triton is started using the âmodel-repository option. The âmodel-repository\u001b[0m\n",
       "\u001b[30;48;2;144;144;144moption                                                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">from one or more model repositories that are specified when the server is started. While Triton is running, the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">models being served can be modified as described in Model Management. Repository Layout# These repository paths are</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">specified when Triton is started using the âmodel-repository option. The âmodel-repository option              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDecoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mRepository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mTensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodel repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfrom one or more model repositories that are specified when the server is started. While Triton is running, the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodels being served can be modified as described in Model Management. Repository Layout# These repository paths are\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mspecified when Triton is started using the âmodel-repository option. The âmodel-repository option              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Decoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Repository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Cloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">TensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">model repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">from one or more model repositories that are specified when the server is started. While Triton is running, the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">models being served can be modified as described in Model Management. Repository Layout# These repository paths are</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">specified when Triton is started using the âmodel-repository option. The âmodel-repository option,             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDecoupled Model Examples Model Instance Kind Example JAX Example Preprocessing Using Python Backend Example \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mRepository Open issue Model Repository Contents Repository Layout Model Repository Locations Local File System \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mCloud Storage with Environment variables Google Cloud Storage S3 Azure Storage Cloud Storage with Credential file \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m(Beta) Caching of Cloud Storage Model Versions Model Files TensorRT Models ONNX Models TorchScript Models \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mTensorFlow Models OpenVINO Models Python Models DALI Models Model Repository# Is this your first time setting up a \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodel repository? Check out these tutorials to begin your Triton journey! The Triton Inference Server serves models\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfrom one or more model repositories that are specified when the server is started. While Triton is running, the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmodels being served can be modified as described in Model Management. Repository Layout# These repository paths are\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mspecified when Triton is started using the âmodel-repository option. The âmodel-repository option,             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Source : </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Source : \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">     \"hypothesis\": You can specify the location of the model repository in Triton Inference Server using the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">--model-repository option when starting the server. This option allows you to specify one or more model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">repositories that the server will serve models from. You can also modify the models being served while the server </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">is running using Model Management. For more information, please refer to the Triton Inference Server documentation,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">specifically the Architecture section: </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">\"entails\":                                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m     \"hypothesis\": You can specify the location of the model repository in Triton Inference Server using the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m--model-repository option when starting the server. This option allows you to specify one or more model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mrepositories that the server will serve models from. You can also modify the models being served while the server \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mis running using Model Management. For more information, please refer to the Triton Inference Server documentation,\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mspecifically the Architecture section: \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m\"entails\":                                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">Yes.                                                                                                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mYes.                                                                                                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.654</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'Yes.', 'token_usage': {'prompt_tokens': 811, 'total_t</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.654\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'Yes.', 'token_usage': {'prompt_tokens': 811, 'total_t\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.658</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 0.97 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.658\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 0.97 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.661</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">InternalSystemActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '8c72...', 'action_uid': '6848...', 'action_name': 'sel</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.661\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mInternalSystemActionFinished\u001b[0m | \u001b[2m{'uid': '8c72...', 'action_uid': '6848...', 'action_name': 'sel\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.664</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '0f17...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.664\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '0f17...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.666</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.666\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.667</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">OutputRailFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7176...', 'flow_id': 'self check facts'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.667\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mOutputRailFinished\u001b[0m | \u001b[2m{'uid': '7176...', 'flow_id': 'self check facts'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.669</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'abed...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.669\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'abed...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.671</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.671\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.673</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">OutputRailsFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'e9a9...'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.673\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mOutputRailsFinished\u001b[0m | \u001b[2m{'uid': 'e9a9...'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.675</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '01eb...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.675\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '01eb...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.677</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.677\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.678</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartUtteranceBotAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '814c...', 'script': 'You can specify the location of the mo</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.678\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartUtteranceBotAction\u001b[0m | \u001b[2m{'uid': '814c...', 'script': 'You can specify the location of the mo\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:35.683</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Total processing took 7.86 seconds. LLM Stats: 3 total calls, 6.96 total time, 2234 total tokens, 21</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:35.683\u001b[0m | \u001b[2;38;2;85;85;85mTotal processing took 7.86 seconds. LLM Stats: 3 total calls, 6.96 total time, 2234 total tokens, 21\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can specify the location of the model repository in Triton Inference Server using the --model-repository option when starting the server. This option allows you to specify one or more model repositories that the server will serve models from. You can also modify the models being served while the server is running using Model Management. For more information, please refer to the Triton Inference Server documentation, specifically the Architecture section: https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html\n"
     ]
    }
   ],
   "source": [
    "outputs = rails.generate(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"how can I specify the location of the model repository in triton-inference-server\",\n",
    "        }\n",
    "    ],\n",
    "    options={\n",
    "        \"output_vars\": True,\n",
    "        \"llm_output\": True,\n",
    "        \"log\": {\n",
    "            \"activated_rails\": True,\n",
    "            \"llm_calls\": True,\n",
    "            \"internal_events\": True,\n",
    "            \"colang_history\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print(outputs.response[0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As outlined in the main documentation, the purpose of the [Fact-Checking Rails](https://docs.nvidia.com/nemo/guardrails/user_guides/guardrails-library.html#fact-checking) is to verify that the messages generated by the bot comply with the knowledge base. If the bot's messages contain information (correct or incorrect) that is not present in the knowledge base, the self check fact rails will prevent the output from being displayed to the user.\n",
    "\n",
    "In the following example, the bot message, although correct, was blocked because the knowledge base only contains information about NVIDIA Triton, while the question/answer was related to CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.911</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UtteranceUserActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'final_transcript': 'how do I build custom cuda kernel ?'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.911\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUtteranceUserActionFinished\u001b[0m | \u001b[2m{'final_transcript': 'how do I build custom cuda kernel ?'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.917</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'fdbb...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.917\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'fdbb...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.921</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.921\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.922</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UserMessage</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '9495...', 'text': 'how do I build custom cuda kernel ?'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.922\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUserMessage\u001b[0m | \u001b[2m{'uid': '9495...', 'text': 'how do I build custom cuda kernel ?'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.924</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'eca7...', 'action_name': 'generate_user_intent', 'action_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.924\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'eca7...', 'action_name': 'generate_user_intent', 'action_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.926</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">generate_user_intent</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.926\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mgenerate_user_intent\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.927</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Phase 1</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Generating user intent</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.927\u001b[0m | \u001b[2;38;2;112;112;112mPhase 1\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mGenerating user intent\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:47.940</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:47.940\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System                                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "System                                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are an useful bot that reply to user questions in a useful and truthful way.                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are an useful bot that reply to user questions in a useful and truthful way.                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">If the question uses harmful of violent language, the bot politely refuse to answer.                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mIf the question uses harmful of violent language, the bot politely refuse to answer.                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Your task is to generate the user intent in a conversation given the last user message similar to the examples </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">below.                                                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYour task is to generate the user intent in a conversation given the last user message similar to the examples \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mbelow.                                                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Do not provide any explanations, just output the user intent.                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDo not provide any explanations, just output the user intent.                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\"># Examples:                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m# Examples:                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"What can you do?\"                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"What can you do?\"                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"tell me about you\"                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"tell me about you\"                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"Hello\"                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"Hello\"                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"Hi\"                                                                                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"Hi\"                                                                                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User message: \"tell me what you can do\"                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser message: \"tell me what you can do\"                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask capabilities                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask capabilities                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Hello there!                                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mHello there!                                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: express greeting                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: express greeting                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: express greeting                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: express greeting                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"Hello! How can I assist you today?\"                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"Hello! How can I assist you today?\"                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">What can you do for me?                                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mWhat can you do for me?                                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">User intent: ask about capabilities                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mUser intent: ask about capabilities                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond about capabilities                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond about capabilities                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">various topics, generating text for various purposes and providing suggestions based on your preferences.\"         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mvarious topics, generating text for various purposes and providing suggestions based on your preferences.\"         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">how do I build custom cuda kernel ?                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhow do I build custom cuda kernel ?                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot thinking: potential user intents are: ask capabilities, express greeting                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot thinking: potential user intents are: ask capabilities, express greeting                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">User intent: ask information                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mUser intent: ask information                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.925</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'User intent: ask information', 'token_usage': {'promp</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.925\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'User intent: ask information', 'token_usage': {'promp\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.931</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 0.94 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.931\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 0.94 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.934</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">UserIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7464...', 'intent': 'ask information'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.934\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mUserIntent\u001b[0m | \u001b[2m{'uid': '7464...', 'intent': 'ask information'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.938</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '655a...', 'intent': 'respond to question'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.938\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotIntent\u001b[0m | \u001b[2m{'uid': '655a...', 'intent': 'respond to question'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.941</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'f6d8...', 'action_name': 'retrieve_relevant_chunks', 'act</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.941\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'f6d8...', 'action_name': 'retrieve_relevant_chunks', 'act\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:48.943</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">retrieve_relevant_chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:48.943\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mretrieve_relevant_chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:49.459</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">InternalSystemActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '8979...', 'action_uid': '3547...', 'action_name': 'ret</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:49.459\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mInternalSystemActionFinished\u001b[0m | \u001b[2m{'uid': '8979...', 'action_uid': '3547...', 'action_name': 'ret\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:49.472</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '9599...', 'action_name': 'generate_bot_message', 'action_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:49.472\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '9599...', 'action_name': 'generate_bot_message', 'action_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:49.474</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">generate_bot_message</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:49.474\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mgenerate_bot_message\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:49.475</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Phase 3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Generating bot message ...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:49.475\u001b[0m | \u001b[2;38;2;112;112;112mPhase 3\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mGenerating bot message ...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:20:49.487</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:20:49.487\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">System                                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "System                                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are an useful bot that reply to user questions in a useful and truthful way.                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are an useful bot that reply to user questions in a useful and truthful way.                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">If the question uses harmful of violent language, the bot politely refuse to answer.                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mIf the question uses harmful of violent language, the bot politely refuse to answer.                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">This is some relevant context:                                                                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mThis is some relevant context:                                                                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">```markdown                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m```markdown                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Question: how do I build custom cuda kernel ?                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mQuestion: how do I build custom cuda kernel ?                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Citing : included in the docs/examples/model_repository. Before using the repository, you must fetch </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">any missing model definition files from their public model zoos via the provided script. $ cd docs/examples $ </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">./fetch_models.sh Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">it can also work on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">GPUs# Use the following command to run Triton with the example model repository you just created. The NVIDIA </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Container Toolkit must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">GPU should be made available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">tritonserver --model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">above). After you                                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Citing : included in the docs/examples/model_repository. Before using the repository, you must fetch \u001b[0m\n",
       "\u001b[30;48;2;144;144;144many missing model definition files from their public model zoos via the provided script. $ cd docs/examples $ \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m./fetch_models.sh Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mit can also work on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mGPUs# Use the following command to run Triton with the example model repository you just created. The NVIDIA \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mContainer Toolkit must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mGPU should be made available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mtritonserver --model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mabove). After you                                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">included in the docs/examples/model_repository. Before using the repository, you must fetch any missing model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">definition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">following command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">--model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled above). After </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">you                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mincluded in the docs/examples/model_repository. Before using the repository, you must fetch any missing model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mdefinition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mLaunch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mon CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfollowing command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmust be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mavailable to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 tritonserver \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m--model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled above). After \u001b[0m\n",
       "\u001b[30;48;2;144;144;144myou                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">included in the docs/examples/model_repository. Before using the repository, you must fetch any missing model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">definition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">following command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">--model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled above). After </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">you,                                                                                                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mincluded in the docs/examples/model_repository. Before using the repository, you must fetch any missing model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mdefinition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mLaunch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mon CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfollowing command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmust be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mavailable to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 tritonserver \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m--model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled above). After \u001b[0m\n",
       "\u001b[30;48;2;144;144;144myou,                                                                                                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Source : </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Source : \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">```                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m```                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Your task is to generate the bot message in a conversation given the last user message, user intent and bot intent.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYour task is to generate the bot message in a conversation given the last user message, user intent and bot intent.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Similar to the examples below.                                                                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mSimilar to the examples below.                                                                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Do not provide any explanations, just output the bot message.                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mDo not provide any explanations, just output the bot message.                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\"># Examples:                                                                                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m# Examples:                                                                                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform cannot engage with sensitive content                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform cannot engage with sensitive content                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I will not engage with sensitive content.\"                                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I will not engage with sensitive content.\"                                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer unknown                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer unknown                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I don't know the answer to that.\"                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I don't know the answer to that.\"                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer prone to hallucination                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer prone to hallucination                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"The above response may have been hallucinated, and should be independently verified.\"                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"The above response may have been hallucinated, and should be independently verified.\"                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: inform answer prone to hallucination                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: inform answer prone to hallucination                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">using additional sources.\"                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer\u001b[0m\n",
       "\u001b[30;48;2;144;144;144musing additional sources.\"                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: refuse to respond                                                                                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: refuse to respond                                                                                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"I'm sorry, I can't respond to that.\"                                                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"I'm sorry, I can't respond to that.\"                                                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Hello there!                                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mHello there!                                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: express greeting                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: express greeting                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"Hello! How can I assist you today?\"                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"Hello! How can I assist you today?\"                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">What can you do for me?                                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mWhat can you do for me?                                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond about capabilities                                                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond about capabilities                                                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">various topics, generating text for various purposes and providing suggestions based on your preferences.\"         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot message: \"As an AI assistant, I can help you with a wide range of tasks. This includes question answering on \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mvarious topics, generating text for various purposes and providing suggestions based on your preferences.\"         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">how do I build custom cuda kernel ?                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhow do I build custom cuda kernel ?                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bot                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bot                                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Bot intent: respond to question                                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mBot intent: respond to question                                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">Bot message: \"To build a custom CUDA kernel, you would typically start by writing your kernel code in CUDA C or </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">CUDA C++. This code will define the operations that the kernel will perform on the GPU. After writing your kernel </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">code, you would then compile it using the CUDA compiler, nvcc.                                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mBot message: \"To build a custom CUDA kernel, you would typically start by writing your kernel code in CUDA C or \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mCUDA C++. This code will define the operations that the kernel will perform on the GPU. After writing your kernel \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mcode, you would then compile it using the CUDA compiler, nvcc.                                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">Here's a general outline of the steps you could follow to build a custom CUDA kernel:                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mHere's a general outline of the steps you could follow to build a custom CUDA kernel:                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">1. Install the CUDA toolkit and a compatible version of the NVIDIA driver.                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m1. Install the CUDA toolkit and a compatible version of the NVIDIA driver.                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">2. Choose a programming language and development environment that supports CUDA. The most common choice is C or C++</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">with the CUDA extensions.                                                                                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m2. Choose a programming language and development environment that supports CUDA. The most common choice is C or C++\u001b[0m\n",
       "\u001b[30;48;2;0;102;0mwith the CUDA extensions.                                                                                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">3. Write your kernel code, making sure to follow the CUDA programming model and any necessary guidelines for your </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">chosen programming language and development environment.                                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m3. Write your kernel code, making sure to follow the CUDA programming model and any necessary guidelines for your \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mchosen programming language and development environment.                                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">4. Compile your kernel code using nvcc.                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m4. Compile your kernel code using nvcc.                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">5. Integrate your kernel into a larger program or framework, if desired.                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m5. Integrate your kernel into a larger program or framework, if desired.                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">Keep in mind that writing a CUDA kernel can be complex and requires knowledge of both the CUDA programming model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">and the underlying hardware.                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mKeep in mind that writing a CUDA kernel can be complex and requires knowledge of both the CUDA programming model \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mand the underlying hardware.                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">You can also look at the official NVIDIA documentation, in particular the CUDA programming guide and the kernel </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">execution chapter of the CUDA documentation for more information on the syntax and behavior of CUDA kernels.\"      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mYou can also look at the official NVIDIA documentation, in particular the CUDA programming guide and the kernel \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mexecution chapter of the CUDA documentation for more information on the syntax and behavior of CUDA kernels.\"      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.098</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'Bot message: \"To build a custom CUDA kernel, you woul</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.098\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'Bot message: \"To build a custom CUDA kernel, you woul\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.103</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 11.56 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.103\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 11.56 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.105</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM Bot Message Generation call took 11.62 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.105\u001b[0m | \u001b[2;38;2;85;85;85mLLM Bot Message Generation call took 11.62 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.106</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotMessage</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '3b19...', 'text': \"To build a custom CUDA kernel, you would typically st</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.106\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotMessage\u001b[0m | \u001b[2m{'uid': '3b19...', 'text': \"To build a custom CUDA kernel, you would typically st\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.112</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '05e3...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.112\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '05e3...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.114</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.114\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.115</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartOutputRails</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '549f...'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.115\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartOutputRails\u001b[0m | \u001b[2m{'uid': '549f...'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.117</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7969...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.117\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '7969...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.119</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.119\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.120</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartOutputRail</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '5cbf...', 'flow_id': 'self check facts'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.120\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartOutputRail\u001b[0m | \u001b[2m{'uid': '5cbf...', 'flow_id': 'self check facts'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.122</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'bb34...', 'action_name': 'self_check_facts', 'action_para</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.122\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'bb34...', 'action_name': 'self_check_facts', 'action_para\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.124</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">self_check_facts</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.124\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mself_check_facts\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:01.127</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Invocation Params</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'_type': 'chat-nvidia-ai-playground', 'stop': None}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:01.127\u001b[0m | \u001b[2;38;2;112;112;112mInvocation Params\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'_type': 'chat-nvidia-ai-playground', 'stop': None}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">User                                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "User                                                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You are given a task to identify if the hypothesis is grounded and entailed to the evidence.                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou are given a task to identify if the hypothesis is grounded and entailed to the evidence.                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You will only use the contents of the evidence and not rely on external knowledge.                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou will only use the contents of the evidence and not rely on external knowledge.                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Answer with yes/no. \"evidence\":                                                                                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mAnswer with yes/no. \"evidence\":                                                                                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Question: how do I build custom cuda kernel ?                                                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Question: how do I build custom cuda kernel ?                                                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Citing : included in the docs/examples/model_repository. Before using the repository, you must fetch </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">any missing model definition files from their public model zoos via the provided script. $ cd docs/examples $ </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">./fetch_models.sh Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">it can also work on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">GPUs# Use the following command to run Triton with the example model repository you just created. The NVIDIA </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Container Toolkit must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">GPU should be made available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">tritonserver --model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">above). After you                                                                                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Citing : included in the docs/examples/model_repository. Before using the repository, you must fetch \u001b[0m\n",
       "\u001b[30;48;2;144;144;144many missing model definition files from their public model zoos via the provided script. $ cd docs/examples $ \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m./fetch_models.sh Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mit can also work on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mGPUs# Use the following command to run Triton with the example model repository you just created. The NVIDIA \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mContainer Toolkit must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mGPU should be made available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mtritonserver --model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mabove). After you                                                                                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">included in the docs/examples/model_repository. Before using the repository, you must fetch any missing model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">definition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">following command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">--model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled above). After </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">you                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mincluded in the docs/examples/model_repository. Before using the repository, you must fetch any missing model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mdefinition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mLaunch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mon CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfollowing command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmust be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mavailable to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 tritonserver \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m--model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled above). After \u001b[0m\n",
       "\u001b[30;48;2;144;144;144myou                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">included in the docs/examples/model_repository. Before using the repository, you must fetch any missing model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">definition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Launch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">on CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">following command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">must be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">available to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">--model-repository=/models Where &lt;xx.yy&gt; is the version of Triton that you want to use (and pulled above). After </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">you,                                                                                                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mincluded in the docs/examples/model_repository. Before using the repository, you must fetch any missing model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mdefinition files from their public model zoos via the provided script. $ cd docs/examples $ ./fetch_models.sh \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mLaunch Triton# Triton is optimized to provide the best inferencing performance by using GPUs, but it can also work \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mon CPU-only systems. In both cases you can use the same Triton Docker image. Run on System with GPUs# Use the \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mfollowing command to run Triton with the example model repository you just created. The NVIDIA Container Toolkit \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mmust be installed for Docker to recognize the GPU(s). The âgpus=1 flag indicates that 1 system GPU should be made\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mavailable to Triton for inferencing. $ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m-v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:<xx.yy>-py3 tritonserver \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m--model-repository=/models Where <xx.yy> is the version of Triton that you want to use (and pulled above). After \u001b[0m\n",
       "\u001b[30;48;2;144;144;144myou,                                                                                                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">            Source : </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m            Source : \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mhttps://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">     \"hypothesis\": To build a custom CUDA kernel, you would typically start by writing your kernel code in CUDA C </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">or CUDA C++. This code will define the operations that the kernel will perform on the GPU. After writing your </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">kernel code, you would then compile it using the CUDA compiler, nvcc.                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m     \"hypothesis\": To build a custom CUDA kernel, you would typically start by writing your kernel code in CUDA C \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mor CUDA C++. This code will define the operations that the kernel will perform on the GPU. After writing your \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mkernel code, you would then compile it using the CUDA compiler, nvcc.                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Here's a general outline of the steps you could follow to build a custom CUDA kernel:                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mHere's a general outline of the steps you could follow to build a custom CUDA kernel:                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">1. Install the CUDA toolkit and a compatible version of the NVIDIA driver.                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m1. Install the CUDA toolkit and a compatible version of the NVIDIA driver.                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">2. Choose a programming language and development environment that supports CUDA. The most common choice is C or C++</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">with the CUDA extensions.                                                                                          </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m2. Choose a programming language and development environment that supports CUDA. The most common choice is C or C++\u001b[0m\n",
       "\u001b[30;48;2;144;144;144mwith the CUDA extensions.                                                                                          \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">3. Write your kernel code, making sure to follow the CUDA programming model and any necessary guidelines for your </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">chosen programming language and development environment.                                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m3. Write your kernel code, making sure to follow the CUDA programming model and any necessary guidelines for your \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mchosen programming language and development environment.                                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">4. Compile your kernel code using nvcc.                                                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m4. Compile your kernel code using nvcc.                                                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">5. Integrate your kernel into a larger program or framework, if desired.                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144m5. Integrate your kernel into a larger program or framework, if desired.                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">Keep in mind that writing a CUDA kernel can be complex and requires knowledge of both the CUDA programming model </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">and the underlying hardware.                                                                                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mKeep in mind that writing a CUDA kernel can be complex and requires knowledge of both the CUDA programming model \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mand the underlying hardware.                                                                                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">You can also look at the official NVIDIA documentation, in particular the CUDA programming guide and the kernel </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">execution chapter of the CUDA documentation for more information on the syntax and behavior of CUDA kernels. </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #909090\">\"entails\":                                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;144;144;144mYou can also look at the official NVIDIA documentation, in particular the CUDA programming guide and the kernel \u001b[0m\n",
       "\u001b[30;48;2;144;144;144mexecution chapter of the CUDA documentation for more information on the syntax and behavior of CUDA kernels. \u001b[0m\n",
       "\u001b[30;48;2;144;144;144m\"entails\":                                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">LLM Completion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLLM Completion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">No.                                                                                                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mNo.                                                                                                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">The evidence does not provide information on how to build a custom CUDA kernel. The hypothesis provides a general </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">outline of the steps to build a custom CUDA kernel, but this information is not present in the evidence. The </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">evidence appears to be related to running a Triton inference server using Docker and NVIDIA GPUs, but it does not </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #006600\">provide information on building custom CUDA kernels.                                                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;48;2;0;102;0mThe evidence does not provide information on how to build a custom CUDA kernel. The hypothesis provides a general \u001b[0m\n",
       "\u001b[30;48;2;0;102;0moutline of the steps to build a custom CUDA kernel, but this information is not present in the evidence. The \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mevidence appears to be related to running a Triton inference server using Docker and NVIDIA GPUs, but it does not \u001b[0m\n",
       "\u001b[30;48;2;0;102;0mprovide information on building custom CUDA kernels.                                                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.720</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Output Stats</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">{'role': 'assistant', 'content': 'No. \\n\\nThe evidence does not provide information on </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.720\u001b[0m | \u001b[2;38;2;112;112;112mOutput Stats\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85m{'role': 'assistant', 'content': 'No. \\n\\nThe evidence does not provide information on \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.724</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">LLM call took 4.57 seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.724\u001b[0m | \u001b[2;38;2;85;85;85mLLM call took 4.57 seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.725</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">InternalSystemActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '1e07...', 'action_uid': '7442...', 'action_name': 'sel</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.725\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mInternalSystemActionFinished\u001b[0m | \u001b[2m{'uid': '1e07...', 'action_uid': '7442...', 'action_name': 'sel\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.729</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '6a95...', 'intent': 'refuse to respond'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.729\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotIntent\u001b[0m | \u001b[2m{'uid': '6a95...', 'intent': 'refuse to respond'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.731</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'bd3f...', 'action_name': 'retrieve_relevant_chunks', 'act</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.731\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'bd3f...', 'action_name': 'retrieve_relevant_chunks', 'act\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:05.733</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">retrieve_relevant_chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:05.733\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mretrieve_relevant_chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.280</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">InternalSystemActionFinished</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '35c8...', 'action_uid': '4ba4...', 'action_name': 'ret</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.280\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mInternalSystemActionFinished\u001b[0m | \u001b[2m{'uid': '35c8...', 'action_uid': '4ba4...', 'action_name': 'ret\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.308</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'ef03...', 'action_name': 'generate_bot_message', 'action_</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.308\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': 'ef03...', 'action_name': 'generate_bot_message', 'action_\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.310</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">generate_bot_message</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.310\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mgenerate_bot_message\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.311</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Phase 3</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Generating bot message ...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.311\u001b[0m | \u001b[2;38;2;112;112;112mPhase 3\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mGenerating bot message ...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.313</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotMessage</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '2b10...', 'text': \"I'm sorry, I can't respond to that.\"}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.313\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotMessage\u001b[0m | \u001b[2m{'uid': '2b10...', 'text': \"I'm sorry, I can't respond to that.\"}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.316</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartInternalSystemAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '6599...', 'action_name': 'create_event', 'action_params':</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.316\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartInternalSystemAction\u001b[0m | \u001b[2m{'uid': '6599...', 'action_name': 'create_event', 'action_params':\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.318</span> | <span style=\"color: #b7b7b7; text-decoration-color: #b7b7b7\">Executing action</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">create_event</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.318\u001b[0m | \u001b[2;38;2;112;112;112mExecuting action\u001b[0m\u001b[2m \u001b[0m\u001b[2;38;2;85;85;85mcreate_event\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.319</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">StartUtteranceBotAction</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': '7ab4...', 'script': \"I'm sorry, I can't respond to that.\", </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.319\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mStartUtteranceBotAction\u001b[0m | \u001b[2m{'uid': '7ab4...', 'script': \"I'm sorry, I can't respond to that.\", \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.322</span> | <span style=\"color: #7f7fbf; text-decoration-color: #7f7fbf\">Event</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">BotIntent</span> | <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">{'uid': 'bac1...', 'intent': 'stop'}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.322\u001b[0m | \u001b[2;34mEvent\u001b[0m\u001b[2m \u001b[0m\u001b[1;2mBotIntent\u001b[0m | \u001b[2m{'uid': 'bac1...', 'intent': 'stop'}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18:21:06.325</span> | <span style=\"color: #aaaaaa; text-decoration-color: #aaaaaa\">Total processing took 18.41 seconds. LLM Stats: 3 total calls, 17.07 total time, 2862 total tokens, </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m18:21:06.325\u001b[0m | \u001b[2;38;2;85;85;85mTotal processing took 18.41 seconds. LLM Stats: 3 total calls, 17.07 total time, 2862 total tokens, \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I can't respond to that.\n"
     ]
    }
   ],
   "source": [
    "outputs = rails.generate(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"how do I build custom cuda kernel ?\",\n",
    "        }\n",
    "    ],\n",
    "    options={\n",
    "        \"output_vars\": True,\n",
    "        \"llm_output\": True,\n",
    "        \"log\": {\n",
    "            \"activated_rails\": True,\n",
    "            \"llm_calls\": True,\n",
    "            \"internal_events\": True,\n",
    "            \"colang_history\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "print(outputs.response[0][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-gen-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
