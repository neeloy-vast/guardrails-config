{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92201724-fc20-4564-954d-29edcada2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88755d5c-cbe3-4985-a022-b36f59ae944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'element_id': '975678b31c3e6e7cc3b0d2e7c18cb30a', 'cleaned_text': '2024 4 2 0 2 J 6 ] Y C . [ 1 9 2 0 0 0 . 2 0 4 2 : arXiv. X EXPLORING PUBLIC OPINION ON RESPONSIBLE AI THROUGH THE LENS OF CULTURAL CONSENSUS THEORY Necdet G√ºrkan Jordan W. Suchow The School of Business Stevens Institute of Technology ngurkan@stevens.edu The School of Business Stevens Institute of Technology jws@stevens.edu ABSTRACT As the societal implications of Artificial Intelligence (AI) continue to grow, the pursuit of responsible AI necessitates public engagement in its development and governance processes. This involvement is crucial for capturing diverse perspectives and promoting equitable practices and outcomes. We applied Cultural Consensus Theory (CCT) to nationally representative survey dataset on various aspects of AI to discern beliefs and attitudes about responsible AI in the United States. Our results offer valuable insights by identifying shared and contrasting views on responsible AI. Furthermore, these findings serve as critical reference points for developers and policymakers, enabling them to more effectively consider individual variances and group-level cultural perspectives when making significant decisions and addressing the public‚Äô concerns.', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '1'}, {'element_id': 'b6a8237fbb07ec857df42aa61fc5ed39', 'cleaned_text': '5 Results 5.1 Consensus beliefs regarding responsible AI Our iCCT model revealed that representative sample of the U.S. population includes four consensus beliefs concerning various aspects of responsible AI. These findings effectively address our first research question, illustrating that the U.S. population does not possess uniform beliefs about responsible AI (Fig. 1 and Fig. 2). The diverse perspectives emphasize the complexity and nuanced understanding of artificial intelligence within the U.S. populace. Furthermore, it indicates that our society‚Äô discourse around responsible AI is multi-faceted and influenced by variety of factors such as individual differences and cultural constructs. While the number of cultures indicates the number of consensus in the data, it does not inform us about the uniformity of the cultural assignment distribution. An entropy-based metric addresses this problem by estimating the uncertainty of the cultural allocation of an unknown randomly chosen data point given particular distribution of culture assignments. The smaller value of entropy indicates that there are few large clusters, and the larger values of entropy are associated with more evenly distributed cultures. In the analysis, the final cultural assignment is determined by the modal membership across the final 100 posterior samples. Out of 2105 respondents, 1217 respondents were clustered into culture 1, 504 were clustered into culture 2, 218 were clustered into culture 3, and 166 were clustered into culture 4. This can be attributed to the presence of one large cluster (cluster 1, holding approximately 55.3% of the data points), while the remaining clusters are smaller in comparison. The cluster entropy is not exceedingly low due to moderate level of uniformity observed among the three smaller clusters. aga A pra ka A ta all Bee fee ca aoe rae cee 08 ‚Äú feb ‚Äù swe * Consensus values 0 5 10 15 20 25 30 35 40 45 50 55 60 65 Survey item', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '5'}, {'element_id': '02640245be645d7512622e5134698f72', 'cleaned_text': '5.2 Controversial and challenging topics in responsible AI: Inter and intra-cultural consensus beliefs Compared to previous methods, such as segmentation analysis and topic modeling, iCCT is able to identify subjects related to responsible AI where cultural disagreements are most prominent. This is accomplished by focusing on items exhibiting the highest variance among consensus values. In our analysis, we found the consensus beliefs for Q3, which focuses on ‚Äúmanufacturing job automation‚Äù, exhibited the highest variation among the cultures, with respective consensus values of .18, .75, .02, and .94. Automation of manufacturing jobs through the use of artificial intelligence is indeed controversial topic (Wang, 2019). While the prospect of automation in the manufacturing sector poses threat to job security for significant number of workers worldwide, some individuals may perceive it as means to increase efficiency and productivity in manufacturing. 6 Table 1 presents the most controversial aspects of each question across the cultures, revealing that there are subgroups within the population holding different perspectives on ‚Äôsmarter technology‚Äô as potentially detrimental outcome of AI adoption in everyday life. This disparity could account for the nuanced viewpoints regarding the societal implications of AI technologies. In this context, ‚Äôsmarter technology‚Äô not only refers to improvements in efficiency and productivity, but also to broader transformation of societal norms and structures. For instance, these differing attitudes might reflect underlying concerns or optimism about AI‚Äô role in reducing personal interactions, reshaping manufacturing jobs through automation, and posing potential threats to democracy. Some subgroups may perceive these changes as an advancement, while others might view them as loss or risk. Understanding these multifaceted views is key to fostering balanced and inclusive dialogue on the future of AI. These results adequately address the second research question.', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '6'}, {'element_id': '43acafdb4a8b09bdff890b4a89844f1d', 'cleaned_text': 'Views on trusting ‚Äôhigher education institutions‚Äô to regulate the use of artificial intelligence greatly vary among different subgroups within the U.S. population. This divergence may arise from the fact that large portion of AI developments are led by major tech companies rather than academic institutions, and these companies often maintain robust media presence, shaping public opinion and perceptions. Furthermore, the level of trust individuals and groups place in colleges and universities to regulate AI can vary significantly, often influenced by the perceived competency of these institutions in the field of AI. This perception contributes to the divergent views regarding their role in AI governance. In order to answer our third research question, identifying the controversial issues and aspects related to responsible AI can assist developers and policymakers in formulating interventions to mitigate any negative impacts on public attitudes towards responsible AI. Moreover, pinpointing the challenging issues and facets of responsible AI within specific subgroups can offer valuable insights. By focusing on these particular topics, developers and policymakers can potentially prevent further divergence in viewpoints and concentrate on addressing specific concerns. In iCCT, the item difficulty parameter is conceptualized as function of the intrinsic characteristics of question. It can be determined by factors such as the complexity of the topic, the level of knowledge needed to answer it cultural correct, or the degree of ambiguity or contention associated with the issue within the cultural context. Os 04 03 ot\" 8 See, . we st te\\' 02 Log item difficulty 0.0 0.1 02 0 5 10 15 20 25 30 35 40 45 50 55 60 65 Survey item Figure 3: Posterior mean results of the item difficulties for each culture.', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '7'}, {'element_id': 'ae98004b0da1291e17c0c882bb0a350c', 'cleaned_text': 'Female Male 18-34 35-44 45-64 654 Democrat Independent oA Republican 032 008 008 $100k+ 012 027 002 50k ~ 100k 025 0.09 0.06 Under $50k 027 006 01 ‚ÄòAgnostic Al Christian Al Non-Cheistian Atheist Something Else Government 06 omodosg 020 028) 002 04 Homemaker Other Private Sector Retired Selt Employed ‚ÄòStudent 020 016 009 702 Unemployed Black Hispanic Other White Al -00 024 0.10 0.08 1 2c. sek Cultures Figure 4: Demographic Distribution of Cultural Assignments insight illuminates the multifaceted and nuanced nature of responsible AI perceptions in our interconnected society, highlighting that these perceptions are not just products of individual demographic attributes, but also of the shared knowledge and perspectives within our interconnected social fabric. To determine whether the identified cultural clusters correlate with the geographic location of participants, we used the participants‚Äô ZIP codes to map their locations. As depicted in Fig. 5, people‚Äô perception of responsible AI cannot be explained by their geographical location.This conclusion aligns with the insights derived from demographic features. That is, perceptions do not merely originate from individual geographic characteristics, but also embody the collective knowledge and viewpoints prevalent in our intricately interconnected societal structure. Figure 5: Geographic Distribution of Cultural Assignments', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '8'}, {'element_id': '575dac3cd33390f092f46dee484c8039', 'cleaned_text': '6 Discussion This study investigated consensus beliefs regarding responsible AI using nationally representative survey data, yielding valuable insights for developers and policymakers. By extending the Cultural Consensus Theory (CCT) through Bayesian non-parametric process, we demonstrated that the U.S. population holds various attitudes towards responsible 8 AI. Our findings revealed four distinct consensus beliefs regarding various aspects of responsible AI within the population, with one large cluster and three smaller ones. The cluster entropy validates moderate level of uniformity among the three smaller clusters. These insights, thus, emphasize the importance of tailored communication strategies that consider the distinctive beliefs within each cluster to encourage more informed discourse and decision-making regarding responsible AI. While recent research has begun to examine the public‚Äô attitudes towards various aspects of AI [38, 18], these studies have not been able to extract the consensus beliefs of each subgroup and have overlooked individual and group-level differences. By identifying different consensus beliefs among population subgroups, we bring attention to the most controversial topics and aspects of various AI applications, and their impact on public perception. The most controversial issue among the subgroups was the responsible use of AI in automating manufacturing jobs. This discovery highlights the need for policymakers and developers to invest more time in mitigating these divergent concerns to enhance the public‚Äô perception of responsible AI, which is crucial for the successful adoption of such technologies. Therefore, this research reemphasizes the importance of nuanced, stakeholder-oriented approach in the development and regulation of AI, ensuring that the technology progresses in manner that respects societal norms and expectations.', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.00029v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-09-27T15:06:45', 'page_number': '8'}, {'element_id': '949d42fd4456f981c83b7bd61be6a815', 'cleaned_text': 'The second most prevalent theme, found in just over 30% of all re- sponses to the open-ended question, referred to fear of technology; specifically deepfakes and artificial intelligence (AI). There were significant differences by country (ùë• 2 = 84.89, ùëë ùëì = 9, ùëù < 0.001). These responses were the highest across Australia (22.9%), the United States (18.3%), and Mexico (13.4%), and the lowest in France (2.9%) and Belgium (4.4%). References to the futuristic nature of deepfake technology, fear of its capabilities and accessibility, as well as the realness of deepfaked images, showed up across these responses. For example, one man from Mexico (aged 25-34) com- mented on how ‚Äúit is difficult to assimilate [to] these types of tools, before they seemed futuristic but they are already very normal.‚Äù Many respondents disclosed that they were unaware if penal- ties and sanctions were available in their country for deepfakes, while others were concerned with the slow pace of governmental re- sponses. One woman from the United States (aged 55-64) stated that she ‚Äúfeared that politics doesn‚Äô attract enough experts in tech who could help shape policy and procedure on deepfakes . . . and it needs to be something for which governments set as goal to get ahead of and not ignore [or] play catch up.‚Äù Similarly, woman from Den- mark (aged 25-34) emphasized the need to ‚Äúhurry to regulate how people are taking advantage of AI.‚Äù References to internet regula- tion and platform responsibility were found across some responses. For instance, one Australian woman (aged 65+) commented that ‚Äúplatforms need to take more responsibility for content,‚Äù and man from the Netherlands (aged 65+) recommended that this type of content should be ‚Äúimmediately removed by relevant platforms and should be punishable for both maker and distributor.‚Äù', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.01721v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-10-17T03:19:50', 'page_number': '11'}, {'element_id': '44b54e0b4c3524884b1a166fd0bde846', 'cleaned_text': 'landscape poses greater complexity such as the applicability of the EU General Data Protection Rule (GDPR) (P4). Moreover, when interpreting laws from Mexico or Colombia, it is important to consider the unique histories and legal contexts of these countries, which differ from those of the US (P10). ‚Ä¢ Legal sophistication. Our experts noted that the sophistication level of the user should guide the nature of LLM legal advice. As P16 explained, there is difference between ‚Äúgeneral public tools‚Äù and ‚Äúenterprise versions‚Äù for attorneys. Since attorneys bear the ultimate legal liability, professionally-oriented AI tools likely pose fewer risks for misuse. More broadly, P20 suggested that LLM systems could provide more advanced and detailed advice to sophisticated users, like corporate client, who are already familiar with the technology‚Äô limitations and are less likely to misinterpret or misuse the information provided. ‚Ä¢ Access to resources. Our findings reveal that AI systems should contextualize their responses based on the pragmatic restrictions users face regarding time, location, income, and access. If traveling to get medical treatment in foreign countries or retaining public defender are unrealistic options, recommendations presuming those resources could poorly serve the user (P8, P11). The user behavior category emerged as experts emphasized that lawyers should not blindly accept user-provided facts. Instead, lawyers must actively probe and ask questions to construct understanding of situation before offering advice. Our findings reveal four key behavioral dimensions for LLM systems to assess: ‚Ä¢ Ambiguity. Experts stated that if user inputs do not provide enough details about the situation, it is either impossible or risky to provide detailed guidance as the LLM outputs are likely to be flawed due to the incomplete information (P1, P6, P13). P1 noted, ‚ÄúSo many facts are missing. I‚Äô so nervous about the idea of the chat [giving] you legal advice [based on this incomplete fact].‚Äù', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.01864v2.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-10-17T04:30:00', 'page_number': '7'}, {'element_id': '5e41977cbfe1b142b908ee54a8a90af8', 'cleaned_text': '(Fast and Horvitz, 2017) and in high-stakes do- mains like healthcare (Sharma et al., 2023) and ed- ucation (Kasneci et al., 2023). Risks of harm from anthropomorphic misconceptions are underscored by regulation that prohibits hidden or undisclosed deployment of AI systems (Mar√©chal, 2016; Lamo and Calo, 2019).', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.02056v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-10-17T07:17:25', 'page_number': '1'}, {'element_id': 'dba4c3d7ec1ad04173d9d83a4b7e0404', 'cleaned_text': 'Ethical Concerns Our results show that GPT-4 is post-conventional moral reasoner (with scores comparable to philoso- phers and graduate students) across most of the languages studied, and it is at least as good as an average adult human for all languages on moral rea- soning tasks. This might lead people to think that GPT-4 or similar models can be used for making real life ethical decisions. However, this could be very dangerous as, firstly, our experimental setup is limited to only 9 dilemmas covering small set of cultural contexts and values; secondly, our ex- periments are limited to 6 languages, which cannot and should not be generalized to the model‚Äô per- formance to other languages beyond those tested. We believe that the current work does not provide sufficient and reliable ground for using LLMs for making moral judgments.', 'file_directory': '/tmp/pdf_chunker', 'filename': '2402.02135v1.pdf', 'filetype': 'application/pdf', 'languages': \"['eng']\", 'last_modified': '2024-10-17T07:45:37', 'page_number': '9'}]\n",
      "                         element_id  \\\n",
      "0  975678b31c3e6e7cc3b0d2e7c18cb30a   \n",
      "1  b6a8237fbb07ec857df42aa61fc5ed39   \n",
      "2  02640245be645d7512622e5134698f72   \n",
      "3  43acafdb4a8b09bdff890b4a89844f1d   \n",
      "4  ae98004b0da1291e17c0c882bb0a350c   \n",
      "5  575dac3cd33390f092f46dee484c8039   \n",
      "6  949d42fd4456f981c83b7bd61be6a815   \n",
      "7  44b54e0b4c3524884b1a166fd0bde846   \n",
      "8  5e41977cbfe1b142b908ee54a8a90af8   \n",
      "9  dba4c3d7ec1ad04173d9d83a4b7e0404   \n",
      "\n",
      "                                        cleaned_text    file_directory  \\\n",
      "0  2024 4 2 0 2 J 6 ] Y C . [ 1 9 2 0 0 0 . 2 0 4...  /tmp/pdf_chunker   \n",
      "1  5 Results 5.1 Consensus beliefs regarding resp...  /tmp/pdf_chunker   \n",
      "2  5.2 Controversial and challenging topics in re...  /tmp/pdf_chunker   \n",
      "3  Views on trusting ‚Äôhigher education institutio...  /tmp/pdf_chunker   \n",
      "4  Female Male 18-34 35-44 45-64 654 Democrat Ind...  /tmp/pdf_chunker   \n",
      "5  6 Discussion This study investigated consensus...  /tmp/pdf_chunker   \n",
      "6  The second most prevalent theme, found in just...  /tmp/pdf_chunker   \n",
      "7  landscape poses greater complexity such as the...  /tmp/pdf_chunker   \n",
      "8  (Fast and Horvitz, 2017) and in high-stakes do...  /tmp/pdf_chunker   \n",
      "9  Ethical Concerns Our results show that GPT-4 i...  /tmp/pdf_chunker   \n",
      "\n",
      "           filename         filetype languages        last_modified  \\\n",
      "0  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "1  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "2  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "3  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "4  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "5  2402.00029v1.pdf  application/pdf   ['eng']  2024-09-27T15:06:45   \n",
      "6  2402.01721v1.pdf  application/pdf   ['eng']  2024-10-17T03:19:50   \n",
      "7  2402.01864v2.pdf  application/pdf   ['eng']  2024-10-17T04:30:00   \n",
      "8  2402.02056v1.pdf  application/pdf   ['eng']  2024-10-17T07:17:25   \n",
      "9  2402.02135v1.pdf  application/pdf   ['eng']  2024-10-17T07:45:37   \n",
      "\n",
      "  page_number  \n",
      "0           1  \n",
      "1           5  \n",
      "2           6  \n",
      "3           7  \n",
      "4           8  \n",
      "5           8  \n",
      "6          11  \n",
      "7           7  \n",
      "8           1  \n",
      "9           9  \n"
     ]
    }
   ],
   "source": [
    "vectordb_url=\"http://vectordb.runai-vast.svc.cluster.local/retrieve-chunks/\"\n",
    "\n",
    "query = \"What did the iCCT model reveal about the U.S. population's beliefs regarding responsible AI?\"\n",
    "\n",
    "query_string = {'query':query}\n",
    "\n",
    "response = requests.post(vectordb_url,json=query_string)\n",
    "\n",
    "#print (response.json()['results'])\n",
    "\n",
    "results = pd.DataFrame(response.json()['results'])\n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cb80841-184d-4924-9f5a-8d3b1c9597fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_url=\"http://rerankqa-mistral-4b.runai-genai.svc.cluster.local/v1/ranking\"\n",
    "\n",
    "start_string = '{\"model\": \"nvidia/nv-rerankqa-mistral-4b-v3\",\"query\": {\"text\":\"' + query + '\"},\"passages\": [{\"text\": \"'\n",
    " \n",
    "middle_string = '\"},{\"text\": \"'.join(results['cleaned_text'])\n",
    "\n",
    "middle_string = middle_string.encode(\"ascii\",\"ignore\")\n",
    "\n",
    "middle_string = middle_string.decode()\n",
    "\n",
    "middle_string = middle_string.replace('\"','')\n",
    "\n",
    "end_string='\"}],\"truncate\": \"END\"}'\n",
    "\n",
    "rerank_string = start_string+middle_string+end_string\n",
    "\n",
    "#print (re\n",
    "\n",
    "json_object = json.loads(rerank_string)\n",
    "\n",
    "#print (json.dumps(json_object, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c330a5f3-1e3d-4bbc-aae9-ad6d081aba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 4 2 0 2 J 6 ] Y C . [ 1 9 2 0 0 0 . 2 0 4 2 : arXiv. X EXPLORING PUBLIC OPINION ON RESPONSIBLE AI THROUGH THE LENS OF CULTURAL CONSENSUS THEORY Necdet G√ºrkan Jordan W. Suchow The School of Business Stevens Institute of Technology ngurkan@stevens.edu The School of Business Stevens Institute of Technology jws@stevens.edu ABSTRACT As the societal implications of Artificial Intelligence (AI) continue to grow, the pursuit of responsible AI necessitates public engagement in its development and governance processes. This involvement is crucial for capturing diverse perspectives and promoting equitable practices and outcomes. We applied Cultural Consensus Theory (CCT) to nationally representative survey dataset on various aspects of AI to discern beliefs and attitudes about responsible AI in the United States. Our results offer valuable insights by identifying shared and contrasting views on responsible AI. Furthermore, these findings serve as critical reference points for developers and policymakers, enabling them to more effectively consider individual variances and group-level cultural perspectives when making significant decisions and addressing the public‚Äô concerns.\n",
      "   index      logit\n",
      "0      0  27.171875\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.post(rerank_url, headers=headers, data=rerank_string)\n",
    "\n",
    "ranking = pd.DataFrame(response.json()['rankings'])\n",
    "\n",
    "citing_text = \"\"\n",
    "\n",
    "if ranking['logit'].loc[0] > 10:\n",
    "    citing_text = results['cleaned_text'].loc[ranking['index'].loc[0]]\n",
    "\n",
    "print(citing_text)\n",
    "\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcff894-dade-46ee-886f-1675ce5fa739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
